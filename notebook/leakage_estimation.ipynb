{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakage esitimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:11:58.050068Z",
     "start_time": "2020-10-08T02:11:58.038641Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from converter import convert_func\n",
    "import scipy.stats as stats\n",
    "from glob import glob\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\"\"\"\n",
    "1. Generate _cs_nt_Pixel_eDep.csv using Geant4\n",
    "2. Save noise data as npy in data_xu_R using parameter_estimation.ipynb\n",
    "3. Generate noisy movie using gamma_noise_image_convert.ipynb \n",
    "4. Estimate leakage points using leakage_estimation.ipynb\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_leaks =[\n",
    "    np.array([-2.0, 1.5]),\n",
    "    np.array([-0.5, 1.0]),\n",
    "    np.array([1.5, 0.5])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterdrop stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_frames = {}\n",
    "# for side in [\"L\", \"R\"]:\n",
    "#     subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "#     subtractor.setNMixtures(1)\n",
    "    \n",
    "#     fname = f\"./turbine_testv5_{side}_0010-0082_noisy.mp4\"\n",
    "#     cap = cv2.VideoCapture(fname)\n",
    "#     noisy_frames[side] = []\n",
    "#     noisy_frames[side+\"_fg\"] = []\n",
    "#     #\n",
    "#     while True:\n",
    "#         ret, img = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         fg = subtractor.apply(img)\n",
    "#         noisy_frames[side].append(img)\n",
    "#         noisy_frames[side+\"_fg\"].append(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgL, imgR = noisy_frames[\"L\"], noisy_frames[\"R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for it_l, it_r in zip(imgL, imgR):\n",
    "#     viz = np.zeros_like(it_l)\n",
    "#     cv2.imshow('img_L', it_l)\n",
    "#     cv2.imshow('img_R', it_r)\n",
    "#     it_l = cv2.cvtColor(it_l, cv2.COLOR_BGR2GRAY)\n",
    "#     it_r = cv2.cvtColor(it_r, cv2.COLOR_BGR2GRAY)\n",
    "#     viz[..., 1] = it_l\n",
    "#     viz[..., 2] = it_r\n",
    "#     cv2.imshow('viz', viz)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == 27:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgL, fgR = noisy_frames[\"L_fg\"], noisy_frames[\"R_fg\"]\n",
    "# for it_l, it_r in zip(fgL, fgR):\n",
    "#     cv2.imshow('img_L', it_l)\n",
    "#     cv2.imshow('img_R', it_r)\n",
    "#     key = cv2.waitKey(0)\n",
    "#     if key == 27:\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.array(fgL).mean(0).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.array(fgR).mean(0).mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic raindrop detection\n",
    "\n",
    "## Detect raindrop lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_frames ={}\n",
    "num_frame = 24\n",
    "for side in [\"L\", \"R\"]:\n",
    "    # Video to images\n",
    "    noisy_frames[side] = []\n",
    "    noisy_frames[side+\"_color\"] = []\n",
    "    fname = f\"./turbine_testv5_{side}_0010-0082_noisy.mp4\"\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        noisy_frames[side+\"_color\"].append(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        noisy_frames[side].append(img)\n",
    "\n",
    "    # Obtain background image\n",
    "    imgs = noisy_frames[side][:num_frame]\n",
    "    bkg = np.median(imgs, axis=0).astype(np.uint8)\n",
    "    noisy_frames[side+\"_bkg\"] = bkg\n",
    "    \n",
    "    # Get foreground\n",
    "    noisy_frames[side+\"_fg\"] = []\n",
    "    for it in imgs:\n",
    "        diff = np.abs(it/255-bkg/255)\n",
    "        noisy_frames[side+\"_fg\"].append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save noisy color images for paper\n",
    "for side in [\"L\", \"R\"]:\n",
    "    for i in range(5, 10):\n",
    "        cv2.imwrite(f\"paper/exp_noisy{side}_color{i}.jpg\", noisy_frames[side+\"_color\"][i])\n",
    "        fg_img = 15*(255*noisy_frames[side+\"_fg\"][i]).astype(np.uint8)\n",
    "        cv2.imwrite(f\"paper/exp_noisy{side}_fg{i}_contrastAdj.jpg\", fg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font=\"Times New Roman\")\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "# plt.style.use(['science','ieee']) #latex is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raindrop_idx = {}\n",
    "fig, ax = plt.subplots(1, 2, figsize=(7, 2)) # \n",
    "for i, side in enumerate([\"L\", \"R\"]):\n",
    "    plt.figure()\n",
    "    col_aggre = np.array(noisy_frames[side+\"_fg\"]).mean(0).mean(0)\n",
    "    ax[i].plot(col_aggre)\n",
    "    ax[i].set_ylim([0, 0.011])\n",
    "    ax[i].set_xlim([0, noisy_frames['L'][0].shape[1]])\n",
    "    if i==0:\n",
    "        ax[i].set_ylabel('Aggregated value')\n",
    "        ax[i].set_xlabel('Column index of left images')\n",
    "    else:\n",
    "        ax[i].set_xlabel('Column index of right images')\n",
    "    \n",
    "    \n",
    "    # threshold 2 sigma\n",
    "    thresh = col_aggre.mean() + 2*col_aggre.std()\n",
    "    print(thresh)\n",
    "    ax[i].plot(np.full_like(col_aggre, thresh))\n",
    "    \n",
    "    # non-maximum suppression\n",
    "    search_width =5 # \n",
    "    nms_idx = []\n",
    "    for idx in np.where(col_aggre>thresh)[0]:\n",
    "        if col_aggre[idx] == col_aggre[idx-search_width:idx+search_width+1].max():\n",
    "            nms_idx.append(idx)\n",
    "            \n",
    "    print(nms_idx)\n",
    "    raindrop_idx[side] = nms_idx\n",
    "\n",
    "# fig.tight_layout()\n",
    "# Save file\n",
    "# fig.savefig(\"exp_column_feature.pdf\", bbox_inches='tight')\n",
    "fig.savefig(\"exp_column_feature.svg\", format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find line match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_len = [(len(val), key) for key, val in raindrop_idx.items()]\n",
    "features = {}\n",
    "side_ascend = []\n",
    "for _, side in sorted(side_len):\n",
    "    print(side)\n",
    "    print(raindrop_idx[side])\n",
    "    features[side] = np.array(noisy_frames[side+\"_fg\"])[:,:,raindrop_idx[side]]\n",
    "    side_ascend.append(side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process one by one and select match by choosing mode\n",
    "match_accum = []\n",
    "for t in range(features[side].shape[0]):\n",
    "    print(\"processing:\", t)\n",
    "    dist_mat = features[side_ascend[0]][t].T[:, None, :] -  features[side_ascend[1]][t].T[None, :, :]\n",
    "    dist_mat = np.linalg.norm(dist_mat, ord=1, axis=-1)\n",
    "    match_idx = np.argmin(dist_mat, axis=1)\n",
    "    match_accum.append(match_idx)\n",
    "    \n",
    "match_accum = np.array(match_accum)\n",
    "match_ret, _ = stats.mode(match_accum, axis=0)\n",
    "match_ret = match_ret.flatten().tolist()\n",
    "print(\"Find match:\", side_ascend, list(enumerate(match_ret)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lines(lines):\n",
    "    mat = []\n",
    "    for line in lines:\n",
    "        parsed_line = line[line.find('(')+1:line.find(')')].split(\", \")\n",
    "        data = list(map(float, parsed_line))\n",
    "        mat.append(data)\n",
    "    return np.array(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load blender camera info\n",
    "blender_mat = {}\n",
    "for fname in glob(\"./blender_camera/*.matrix\"):\n",
    "    print(fname)\n",
    "    with open(fname) as f:\n",
    "        lines = f.readlines()\n",
    "    mat = parse_lines(lines)\n",
    "    \n",
    "    mat_name = os.path.split(fname)[-1].split('.')[0]\n",
    "    blender_mat[mat_name] = mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blender_mat[\"P_L\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_side = side_ascend[0]\n",
    "b_side = side_ascend[1]\n",
    "a_rain_idx = raindrop_idx[side_ascend[0]]\n",
    "b_rain_idx = raindrop_idx[side_ascend[1]]\n",
    "\n",
    "pred_leaks= []\n",
    "for a, b in enumerate(match_ret):\n",
    "    print(a_rain_idx[a], b_rain_idx[b])\n",
    "    print(side_ascend)\n",
    "    \n",
    "    # Waterdrop estimation in image coord (x, y, 1)\n",
    "    line_in_a = np.cross(np.array([a_rain_idx[a], 100, 1]), np.array([a_rain_idx[a], 0, 1]))\n",
    "    print(f\"line_in_a:{line_in_a}\")\n",
    "    line_in_b = np.cross(np.array([b_rain_idx[b], 100, 1]), np.array([b_rain_idx[b], 0, 1]))\n",
    "    print(f\"line_in_b:{line_in_b}\")\n",
    "\n",
    "    # Get projection matrix\n",
    "    P_a = blender_mat[f\"P_{a_side}\"]\n",
    "    P_b = blender_mat[f\"P_{b_side}\"]\n",
    "    # Back projection PI(4x1)=P(3x4)_t * I(3x1)\n",
    "    PI_a = P_a.T.dot(line_in_a)\n",
    "    PI_b = P_b.T.dot(line_in_b)\n",
    "    intersection_line = np.vstack([PI_a, PI_b])\n",
    "\n",
    "    # Estimate raindrop location based on camera location\n",
    "    cam_z = 3.0\n",
    "    # Solve Ax=b -> intersection_line[:,:2].dot(X) = -intersection_line[:,2:].dot(np.array([cam_z, 1]))\n",
    "    pred_leak = np.linalg.solve(intersection_line[:,:2], -intersection_line[:,2:].dot(np.array([cam_z, 1])))\n",
    "    print(\"Estimation leakage:\", pred_leak)\n",
    "    pred_leaks.append(pred_leak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_leaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, gt in zip(pred_leaks, gt_leaks):\n",
    "    print(f\"L2 norm: {np.linalg.norm(pred-gt):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
